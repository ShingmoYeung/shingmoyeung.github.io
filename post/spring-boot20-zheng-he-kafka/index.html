<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>代码人生</title>
<meta name="description" content="代码 人生 感悟 分享" />
<link rel="shortcut icon" href="https://shingmoyeung.github.io/favicon.ico?v=1603860705952">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.2/animate.min.css">

<link rel="stylesheet" href="https://shingmoyeung.github.io/styles/main.css">


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-148889074-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-148889074-1');
</script>


  </head>
  <body>
    <div id="app" class="main px-4 flex flex-col lg:flex-row">
      <div id="sidebar" class="sidebar-wrapper lg:static lg:w-1/4">
  <div class="lg:sticky top-0">
    <div class="sidebar-content">
      <div class="flex lg:block p-4 lg:px-0 items-center fixed lg:static lg:block top-0 right-0 left-0 bg-white z-50">
        <i class="ri-menu-2-line lg:mt-4 text-2xl cursor-pointer animated fadeIn" onclick="openMenu()"></i>
        <a href="https://shingmoyeung.github.io">
          <img class="animated fadeInLeft avatar rounded-lg mx-4 lg:mt-32 lg:mx-0 mt-0 lg:w-24 lg:h-24 w-12 w-12" src="https://shingmoyeung.github.io/images/avatar.png?v=1603860705952" alt="">
        </a>
        <h1 class="animated fadeInLeft lg:text-4xl font-extrabold lg:mt-8 mt-0 text-xl" style="animation-delay: 0.2s">代码人生</h1>
      </div>
      
        <div class="animated fadeInLeft" style="animation-delay: 0.4s">
          <p class="my-4 text-gray-600 font-light hidden lg:block">
            文章目录
          </p>
          <div class="toc-container hidden lg:block">
            <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#kafka-%E6%A6%82%E8%BF%B0">Kafka 概述</a></li>
<li><a href="#kafka-%E7%89%B9%E6%80%A7">Kafka 特性</a></li>
<li><a href="#kafka-%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF">Kafka 使用场景</a></li>
<li><a href="#spring-boot20-kafka">Spring Boot2.0 + Kafka</a>
<ul>
<li><a href="#1%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEkafka-zookeeper">1，安装配置Kafka ,Zookeeper</a></li>
<li><a href="#2%E5%88%9B%E5%BB%BA-spring-boot-%E9%A1%B9%E7%9B%AE">2，创建 Spring Boot 项目</a>
<ul>
<li><a href="#pomxml%E5%BC%95%E7%94%A8">pom.xml引用</a></li>
<li><a href="#%E5%AE%9A%E4%B9%89%E6%B6%88%E6%81%AF%E7%94%9F%E4%BA%A7%E8%80%85">定义消息生产者</a></li>
<li><a href="#%E5%AE%9A%E4%B9%89%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E8%80%85">定义消息消费者</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%8D%E4%B8%A2%E5%A4%B1">Kafka如何保证数据的不丢失</a>
<ul>
<li><a href="#1%E7%94%9F%E4%BA%A7%E8%80%85%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%8D%E4%B8%A2%E5%A4%B1">1.生产者数据的不丢失</a></li>
<li><a href="#2%E6%B6%88%E8%B4%B9%E8%80%85%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%8D%E4%B8%A2%E5%A4%B1">2.消费者数据的不丢失</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      
    </div>
  </div>
</div>

<div class="menu-container">
  <i class="ri-arrow-left-line text-2xl cursor-pointer animated fadeIn close-menu-btn" onclick="closeMenu()"></i>
  <div>
    
      
        <a href="/" class="menu" style="animation-delay: 0s">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu" style="animation-delay: 0.2s">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu" style="animation-delay: 0.4s">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu" style="animation-delay: 0.6000000000000001s">
          关于
        </a>
      
    
  </div>
  <div class="site-footer">
    <div class="py-4 text-gray-700">Powered by <a href="https://www.codingforever.cn/" target="_blank">The Code of Life</a><br/><br/><b>友情链接</b><br/><a href="https://kalasearch.cn" target="_blank">卡拉搜索</a></div>
    <a class="rss" href="https://shingmoyeung.github.io/atom.xml" target="_blank">RSS</a>
  </div>
</div>
<div class="mask" onclick="closeMenu()">
</div>
      <div class="content-wrapper py-32 lg:p-8 lg:w-3/4 post-detail animated fadeIn">
        <h1 class="text-3xl font-bold lg:mt-16">Spring Boot2.0 整合 Kafka</h1>
        <div class="text-sm text-gray-700 lg:my-8">
          2018-11-29 13:12 / 9 min read
        </div>
        
        <div class="post-content yue">
          <h2 id="kafka-概述">Kafka 概述</h2>
<p>  Apache Kafka 是一个分布式流处理平台，用于构建实时的数据管道和流式的应用.它可以让你发布和订阅流式的记录，可以储存流式的记录，并且有较好的容错性，可以在流式记录产生时就进行处理。<br>
  Apache Kafka是分布式发布-订阅消息系统，在 kafka官网上对 Kafka 的定义：一个分布式发布-订阅消息传递系统。</p>
<h2 id="kafka-特性">Kafka 特性</h2>
<pre><code>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作；
可扩展性：kafka集群支持热扩展；
持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失；
容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）；
高并发：支持数千个客户端同时读写；
支持实时在线处理和离线处理：可以使用Storm这种实时流处理系统对消息进行实时进行处理，同时还可以使用Hadoop这种批处理系统进行离线处理；
</code></pre>
<h2 id="kafka-使用场景">Kafka 使用场景</h2>
<pre><code>日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如Hadoop、Hbase、Solr等；
消息系统：解耦和生产者和消费者、缓存消息等；
用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到Hadoop、数据仓库中做离线分析和挖掘；
运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；
流式处理：比如spark streaming和storm；
事件源；
</code></pre>
<h2 id="spring-boot20-kafka">Spring Boot2.0 + Kafka</h2>
<h3 id="1安装配置kafka-zookeeper">1，安装配置Kafka ,Zookeeper</h3>
<p>安装和配置过程很简单，就不详细说了，参考官网：http://kafka.apache.org/quickstart<br>
使用命令启动Kafka：</p>
<pre><code class="language-shell">bin``/kafka-server-start``.sh config``/server``.properties
</code></pre>
<p>下面给出我的环境：<br>
Centos 7.5,  Kafka 2.11, Zookeeper-3.4.13,  JDK1.8+</p>
<h3 id="2创建-spring-boot-项目">2，创建 Spring Boot 项目</h3>
<p>注意版本：该项目使用Spring Boot 2.0 +，低版本可能不对</p>
<h4 id="pomxml引用">pom.xml引用</h4>
<pre><code class="language-maven">               &lt;dependency&gt;
                   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                   &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
               &lt;/dependency&gt;
               &lt;dependency&gt;
                   &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;
                   &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;
               &lt;/dependency&gt;
               &lt;dependency&gt;
                   &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
                   &lt;artifactId&gt;fastjson&lt;/artifactId&gt;
                   &lt;version&gt;1.2.47&lt;/version&gt;
               &lt;/dependency&gt;
</code></pre>
<h4 id="定义消息生产者">定义消息生产者</h4>
<p>直接使用 KafkaTemplate 发送消息 ，Spring Boot自动装配，不需要自己定义一个Kafka配置类，吐槽一下网站的文章，全都是互相抄，全都写一个 ProduceConfig Consumerconfig 类, Kafka 的参数配置 硬编码在代码中，简直无法直视。。<br>
定义一个泛型类KafkaSender<T> T 就是你需要发送的消息 对象，序列化使用阿里的 fastjson<br>
消息发送后，可以在回调类里面处理自己的业务，ListenableFutureCallback 类有两个方法，分别是 onFailureon 和 onSuccess ，实际场景可以在这两个方法，处理自己的具体业务，这里不做实现。</p>
<pre><code class="language-java">       /**
        * 消息生产者
        *
        * @author Jarvis
        * @date 2018/8/3
        */
       @Component
       public class KafkaSender&lt;T&gt; {
       
           private Logger logger = LoggerFactory.getLogger(KafkaSender.class);
       
           @Autowired
           private KafkaTemplate&lt;String, Object&gt; kafkaTemplate;
       
           /**
            * kafka 发送消息
            *
            * @param obj 消息对象
            */
           public void send(T obj) {
               String jsonObj = JSON.toJSONString(obj);
               logger.info(&quot;------------ message = {}&quot;, jsonObj);
       
               //发送消息
               ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; future = kafkaTemplate.send(&quot;kafka.tut&quot;, jsonObj);
               future.addCallback(new ListenableFutureCallback&lt;SendResult&lt;String, Object&gt;&gt;() {
                   @Override
                   public void onFailure(Throwable throwable) {
                       logger.info(&quot;Produce: The message failed to be sent:&quot; + throwable.getMessage());
                   }
       
                   @Override
                   public void onSuccess(SendResult&lt;String, Object&gt; stringObjectSendResult) {
                       //TODO 业务处理
                       logger.info(&quot;Produce: The message was sent successfully:&quot;);
                       logger.info(&quot;Produce: _+_+_+_+_+_+_+ result: &quot; + stringObjectSendResult.toString());
                   }
               });
           }
       }
</code></pre>
<h4 id="定义消息消费者">定义消息消费者</h4>
<p>使用@KafkaListener 注解监听 topics 消息，此处的topics 必须和 send 函数中的 一致<br>
@Header(KafkaHeaders.RECEIVED_TOPI 直接获取 topic</p>
<pre><code class="language-java">    /**
     * 监听kafka.tut 的 topic
     *
     * @param record
     * @param topic  topic
     */
    @KafkaListener(id = &quot;tut&quot;, topics = &quot;kafka.tut&quot;)
    public void listen(ConsumerRecord&lt;?, ?&gt; record, @Header(KafkaHeaders.RECEIVED_TOPIC) String topic) {
        //判断是否NULL
        Optional&lt;?&gt; kafkaMessage = Optional.ofNullable(record.value());

        if (kafkaMessage.isPresent()) {
            //获取消息
            Object message = kafkaMessage.get();

            logger.info(&quot;Receive： +++++++++++++++ Topic:&quot; + topic);
            logger.info(&quot;Receive： +++++++++++++++ Record:&quot; + record);
            logger.info(&quot;Receive： +++++++++++++++ Message:&quot; + message);
        }
    }
</code></pre>
<p>配置文件 application.yml</p>
<pre><code class="language-yaml">       spring:
         application:
           name: kafka-tutorial
         kafka:
           # 指定kafka 代理地址，可以多个
           bootstrap-servers: 192.168.10.100:9092
           producer:
             retries: 0
             # 每次批量发送消息的数量
             batch-size: 16384
             # 缓存容量
             buffer-memory: 33554432
             # 指定消息key和消息体的编解码方式
             key-serializer: org.apache.kafka.common.serialization.StringSerializer
             value-serializer: org.apache.kafka.common.serialization.StringSerializer
           consumer:
             # 指定默认消费者group id
             group-id: consumer-tutorial
             auto-commit-interval: 100
             auto-offset-reset: earliest
             enable-auto-commit: true
             # 指定消息key和消息体的编解码方式
             key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
             value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
           # 指定listener 容器中的线程数，用于提高并发量
           listener:
             concurrency: 3
直接使用 @Autowired 对类 KafkaSender 自动装配，然后调用 send 方法发送消息即可，下面给出代码：
           @Autowired
           private KafkaSender&lt;User&gt; kafkaSender;
       
           @Test
           public void kafkaSend() throws InterruptedException {
               //模拟发消息
               for (int i = 0; i &lt; 5; i++) {
       
                   User user = new User();
                   user.setId(System.currentTimeMillis());
                   user.setMsg(UUID.randomUUID().toString());
                   user.setSendTime(new Date());
       
                   kafkaSender.send(message);
                   Thread.sleep(3000);
       
               }
           }
</code></pre>
<p>控制台可以看到执行成功：<br>
<img src="https://shingmoyeung.github.io/post-images/1569820698872.png" alt="" loading="lazy"><br>
在服务器执行</p>
<pre><code class="language-shell">bin/kafka-topics.sh --list --zookeeper localhost:2181 
</code></pre>
<p>可以看到topic<br>
<img src="https://shingmoyeung.github.io/post-images/1569820729172.png" alt="" loading="lazy"></p>
<h2 id="kafka如何保证数据的不丢失">Kafka如何保证数据的不丢失</h2>
<h3 id="1生产者数据的不丢失">1.生产者数据的不丢失</h3>
<pre><code>新版本的producer采用异步发送机制。KafkaProducer.send(ProducerRecord)方法仅仅是把这条消息放入一个缓存中(即RecordAccumulator，本质上使用了队列来缓存记录)，同时后台的IO线程会不断扫描该缓存区，将满足条件的消息封装到某个batch中然后发送出去。显然，这个过程中就有一个数据丢失的窗口：若IO线程发送之前client端挂掉了，累积在accumulator中的数据的确有可能会丢失。 kafka的ack机制：在kafka发送数据的时候，每次发送消息都会有一个确认反馈机制，确保消息正常的能够被收到。
如果是同步模式：ack机制能够保证数据的不丢失，如果ack设置为0，风险很大，一般不建议设置为0
producer.type=sync
request.required.acks=1
如果是异步模式：通过buffer来进行控制数据的发送，有两个值来进行控制，时间阈值与消息的数量阈值，如果buffer满了数据还没有发送出去，如果设置的是立即清理模式，风险很大，一定要设置为阻塞模式
producer.type=async
request.required.acks=1
queue.buffering.max.ms=5000
queue.buffering.max.messages=10000
queue.enqueue.timeout.ms = -1
batch.num.messages=200
结论：producer有丢数据的可能，但是可以通过配置保证消息的不丢失
</code></pre>
<h3 id="2消费者数据的不丢失">2.消费者数据的不丢失</h3>
<pre><code>如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失。由于Kafka consumer默认是自动提交位移的，所以在后台提交位移前一定要保证消息被正常处理了，因此不建议采用很重的处理逻辑，如果处理耗时很长，则建议把逻辑放到另一个线程中去做。为了避免数据丢失，现给出两点建议：
enable.auto.commit=false 关闭自动提交位移
在消息被完整处理之后再手动提交位移
如果使用了storm，要开启storm的ackfail机制；
如果没有使用storm，确认数据被完成处理之后，再更新offset值。低级API中需要手动控制offset值。通过offset commit 来保证数据的不丢失，kafka自己记录了每次消费的offset数值，下次继续消费的时候，接着上次的offset进行消费即可。
源码 github：https://github.com/jarvisqi/java-tutorial/tree/master/kafka-tutorial
</code></pre>
<blockquote>
<p>参考：<br>
http://kafka.apache.org/quickstart<br>
https://docs.spring.io/spring-kafka/reference/htmlsingle/#kafka<br>
https://blog.csdn.net/tzs_1041218129/article/details/78988439</p>
</blockquote>

        </div>

        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="https://shingmoyeung.github.io/tag/K43uIohlj/">
            <span class="flex-auto">kafka</span>
          </a>
        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="https://shingmoyeung.github.io/tag/n1fSulW2tB/">
            <span class="flex-auto">SpringBoot</span>
          </a>
        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="https://shingmoyeung.github.io/tag/1p3HLnMJ92/">
            <span class="flex-auto">2018-11</span>
          </a>
        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="https://shingmoyeung.github.io/tag/xiao-xi-dui-lie/">
            <span class="flex-auto">消息队列</span>
          </a>
        
          <a class="animated fadeInUp p-2 items-center text-sm text-gray-700 border hover:bg-gray-300 leading-none rounded-full flex lg:inline-flex m-4 " href="https://shingmoyeung.github.io/tag/dai-ma-na-xie-shi-er/">
            <span class="flex-auto">代码那些事儿</span>
          </a>
        


        <div class="flex justify-between py-8">
          
            <div class="prev-post">
              <a href="https://shingmoyeung.github.io/post/cong-java-dao-golang-kuai-su-ru-men/">
                <h3 class="post-title">
                  <i class="ri-arrow-left-line"></i>
                  从Java到Golang快速入门
                </h3>
              </a>
            </div>
          

          
            <div class="next-post">
              <a href="https://shingmoyeung.github.io/post/spring-kafka-zhong-guan-yu-kafka-de-pei-zhi-can-shu/">
                <h3 class="post-title">
                  Spring Kafka中关于Kafka的配置参数
                  <i class="ri-arrow-right-line"></i>
                </h3>
              </a>
            </div>
          
        </div>

        
          

          
            <link rel="stylesheet" href="https://unpkg.com/disqusjs@1.1/dist/disqusjs.css">
<script src="https://unpkg.com/disqusjs@1.1/dist/disqus.js"></script>

<div id="disqus_thread"></div>

<script>

var options = {
  shortname: 'codingforever',
  apikey: 'Ex7kW5Rj5HlJfSXMDpiO2xzYENfMTeEKV4zLTfgXca2XHftV9fzfjVwrLdrbd16T',
}
if ('') {
  options.api = ''
}
var dsqjs = new DisqusJS(options)

</script>

          
        

      </div>
    </div>

    <script src="https://shingmoyeung.github.io/media/prism.js"></script>  
<script>

Prism.highlightAll()
let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

// This should probably be throttled.
// Especially because it triggers during smooth scrolling.
// https://lodash.com/docs/4.17.10#throttle
// You could do like...
// window.addEventListener("scroll", () => {
//    _.throttle(doThatStuff, 100);
// });
// Only not doing it here to keep this Pen dependency-free.

window.addEventListener("scroll", event => {
  let fromTop = window.scrollY;

  mainNavLinks.forEach((link, index) => {
    let section = document.getElementById(decodeURI(link.hash).substring(1));
    let nextSection = null
    if (mainNavLinks[index + 1]) {
      nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
    }
    if (section.offsetTop <= fromTop) {
      if (nextSection) {
        if (nextSection.offsetTop > fromTop) {
          link.classList.add("current");
        } else {
          link.classList.remove("current");    
        }
      } else {
        link.classList.add("current");
      }
    } else {
      link.classList.remove("current");
    }
  });
});


document.addEventListener("DOMContentLoaded", function() {
  var lazyImages = [].slice.call(document.querySelectorAll(".post-feature-image.lazy"));

  if ("IntersectionObserver" in window) {
    let lazyImageObserver = new IntersectionObserver(function(entries, observer) {
      entries.forEach(function(entry) {
        if (entry.isIntersecting) {
          let lazyImage = entry.target
          lazyImage.style.backgroundImage = `url(${lazyImage.dataset.bg})`
          lazyImage.classList.remove("lazy")
          lazyImageObserver.unobserve(lazyImage)
        }
      });
    });

    lazyImages.forEach(function(lazyImage) {
      lazyImageObserver.observe(lazyImage)
    })
  } else {
    // Possibly fall back to a more compatible method here
  }
});

const menuContainer = document.querySelector('.menu-container')
const menus = document.querySelectorAll('.menu-container .menu')
const mask = document.querySelector('.mask')
const contentWrapper = document.querySelector('.content-wrapper')
const latestArticle = document.querySelector('.latest-article')
const readMore = document.querySelector('.read-more')
const indexPage = document.querySelector('.index-page')

const isHome = location.pathname === '/'
if (latestArticle) {
  latestArticle.style.display = isHome ? 'block' : 'none'
  readMore.style.display = isHome ? 'block' : 'none'
  indexPage.style.display = isHome ? 'none' : 'block'
}

const openMenu = () => {
  menuContainer.classList.add('open')
  menus.forEach(menu => {
    menu.classList.add('animated', 'fadeInLeft')
  })
  mask.classList.add('open')
  contentWrapper.classList.add('is-second')
}

const closeMenu = () => {
  menuContainer.classList.remove('open')
  menus.forEach(menu => {
    menu.classList.remove('animated', 'fadeInLeft')
  })
  mask.classList.remove('open')
  contentWrapper.classList.remove('is-second')
}
</script>
  
  </body>
</html>
